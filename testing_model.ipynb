{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "import model_class\n",
    "reload(model_class)\n",
    "\n",
    "from model_class import *\n",
    "from utils import *\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from itertools import groupby\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model_file_name = 'model-parameters/model.tar'\n",
    "\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 3\n",
    "decoder_n_layers = 3\n",
    "dropout = 0.05\n",
    "attn_model = 'dot'\n",
    "\n",
    "max_length = 4  # Maximum sentence length to consider\n",
    "\n",
    "# Default word tokens\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "num_iters = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate vocabulary\n",
    "voc = Voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model parameters and vocabulary\n",
    "checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "encoder_sd = checkpoint['en']\n",
    "decoder_sd = checkpoint['de']\n",
    "encoder_optimizer_sd = checkpoint['en_opt']\n",
    "decoder_optimizer_sd = checkpoint['de_opt']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize encoder & decoder models & searcher\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "searcher = GreedySearchDecoder(encoder, decoder, device, SOS_token)\n",
    "\n",
    "# Associate loaded parameters\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "decoder.load_state_dict(decoder_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_answers = [get_output(encoder, decoder, searcher, voc, max_length, device, input_sentence='data analyst') \n",
    "               for i in range(num_iters)]\n",
    "\n",
    "prob = {value: round( len(list(freq))/num_iters*100 ) for value, freq in groupby(sorted(all_answers))}\n",
    "sorted_prob = [(k, prob[k]) for k in sorted(prob, key=prob.get, reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
